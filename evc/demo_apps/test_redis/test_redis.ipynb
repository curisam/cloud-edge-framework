{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea1a39d-4330-48a4-b5f2-e80ef334fcf3",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6995094-8dd8-4873-b5c1-dc9e80e853e4",
   "metadata": {},
   "source": [
    "\n",
    "## Load and Save of Torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fb1f0-5eba-49b6-8920-ceef3d687c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "\n",
    "from redisai import Client\n",
    "con = Client(host='evc.re.kr', port=6379)\n",
    "\n",
    "ag_weights = torch.load(\"ag_weights.pt\", map_location=device)\n",
    "torch.save(ag_weights, 'ag_weights2.pt')\n",
    "\n",
    "ag_weights2 = torch.load(\"ag_weights2.pt\", map_location=device)\n",
    "torch.save(ag_weights2, 'ag_weights3.pt')\n",
    "\n",
    "ag_weights3 = torch.load(\"ag_weights3.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db88055-d2ed-4ffa-a6ff-4a31e4d3cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "type( ag_weights3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201bf7f-5a36-43d0-8e2e-0b817205eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch model\n",
    "model_path = os.path.join('ag_weights3.pt')\n",
    "model = open(model_path, 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df8ae6-7d59-4af1-a65a-b600e7b640df",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333531d-9cd2-453b-ae61-ddde6be9c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8451495a-a616-4f7b-8d6b-e7eaffbf9b31",
   "metadata": {},
   "source": [
    "\n",
    "## [문제있음] Save to Redis\n",
    "\n",
    "- Redis 캐시에 저장하고 읽어오는 것은 ok\n",
    "- 읽어온 데이터가 모델로 활용되지 못함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505e813e-3844-4011-a1d0-095dd92b02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis \n",
    "\n",
    "RedisHost = 'evc.re.kr'\n",
    "RedisPort = '20079'\n",
    "RedisPass = 'redis4evc'\n",
    "\n",
    "redis_conn = redis.Redis(\n",
    "    host=RedisHost,\n",
    "    port=RedisPort,\n",
    "    #password=RedisPass,\n",
    "    db=0\n",
    ")\n",
    "\n",
    "key   = 'ag_weights'\n",
    "value = open('ag_weights.pt', 'rb').read()\n",
    "\n",
    "redis_conn.set(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b78ab7a-aaae-4698-8575-51da1c2eeeb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m():\n\u001b[1;32m      2\u001b[0m     redis_conn\u001b[38;5;241m.\u001b[39mtensorset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    redis_conn.tensorset(f'{name}',param.data.numpy().cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6db0e0b-e8e0-485b-935e-46a18b7ea8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "read_weights = redis_conn.get(key)\n",
    "torch.save(read_weights, 'ag_weights_from_redis.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d5cc932-4195-4dda-84bd-d36e655b7233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "\n",
    "pipe = redis_conn.pipeline(transaction=False)\n",
    "pipe = pipe.set('nativeKey', 1)\n",
    "pipe = pipe.set('ag_weights', model)\n",
    "pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af6ef98d-ab33-49ca-8019-af0eb47dcb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline<ConnectionPool<Connection<host=evc.re.kr,port=20079,db=0>>>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pipe.get('ag_weights')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf525b0-e164-450e-b6d6-c852d6eba88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596bbe8c-e468-476c-997c-ec2e7c051c6b",
   "metadata": {},
   "source": [
    "## just test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91361e-8acd-4ed9-af57-2f324df88177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import redis\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "ver = sys.version_info\n",
    "if ver >= (3, 8):\n",
    "    PICKLE_VERSION = 5\n",
    "else:\n",
    "    PICKLE_VERSION = 4\n",
    "\n",
    "CXN = redis.ConnectionPool(host='192.168.1.6', port=6379, db=0)\n",
    "\n",
    "\n",
    "class RedisListObject:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __len__(self):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            return rdb.llen(self.name)\n",
    "\n",
    "    def __setitem__(self, index, value):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            if index >= rdb.llen(self.name):\n",
    "                raise IndexError\n",
    "            with io.BytesIO() as buf:\n",
    "                torch.save(value, buf, pickle_protocol=PICKLE_VERSION, _use_new_zipfile_serialization=True)\n",
    "                if PICKLE_VERSION >= 5:\n",
    "                    rdb.lset(self.name, index, buf.getbuffer())\n",
    "                else:\n",
    "                    rdb.lset(self.name, index, buf.getvalue())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            if not rdb.exists(self.name):\n",
    "                raise redis.DataError(f'Dataset named {self.name} does not exist')\n",
    "            if index >= rdb.llen(self.name):\n",
    "                raise IndexError\n",
    "            with io.BytesIO(rdb.lindex(self.name, index)) as buf:\n",
    "                return torch.load(buf)\n",
    "\n",
    "    def append(self, value):\n",
    "        with io.BytesIO() as buf:\n",
    "            torch.save(value, buf, pickle_protocol=PICKLE_VERSION, _use_new_zipfile_serialization=True)\n",
    "            #print(len(buf.getvalue()))\n",
    "            with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "                func = rdb.rpush if rdb.exists(self.name) else rdb.lpush\n",
    "                if PICKLE_VERSION >= 5:\n",
    "                    func(self.name, buf.getbuffer())\n",
    "                else:\n",
    "                    func(self.name, buf.getvalue())\n",
    "\n",
    "    def delete(self):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            if rdb.exists(self.name):\n",
    "                rdb.delete(self.name)\n",
    "            else:\n",
    "                raise redis.DataError(f'Dataset named {self.name} does not exist')\n",
    "\n",
    "\n",
    "class RedisClient:\n",
    "\n",
    "    def get(self, key):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            if rdb.exists(key):\n",
    "                return RedisListObject(key)\n",
    "            else:\n",
    "                raise redis.DataError(f'Dataset named {key} does not exist')\n",
    "\n",
    "    def set_data_list(self, key, values):\n",
    "        try:\n",
    "            obj = self.get(key)\n",
    "            obj.delete()\n",
    "        except:\n",
    "            obj = RedisListObject(key)\n",
    "\n",
    "        for item in tqdm(values, desc=f\"storing {key}\", dynamic_ncols=True):\n",
    "            obj.append(item)\n",
    "\n",
    "    def keys(self):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            return rdb.keys()\n",
    "\n",
    "    def stats(self):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            try:\n",
    "                return rdb.memory_stats()\n",
    "            except:\n",
    "                return rdb.execute_command('MEMORY STATS')\n",
    "\n",
    "    def check_lens(self, nums):\n",
    "        try:\n",
    "            for k, v in nums.items():\n",
    "                obj = self.get(k)\n",
    "                if v != 0 and len(obj):\n",
    "                    return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def flushdb(self):\n",
    "        with redis.StrictRedis(connection_pool=CXN) as rdb:\n",
    "            rdb.flushdb()\n",
    "\n",
    "\n",
    "if True:\n",
    "    c = RedisClient()\n",
    "    print(c.stats())\n",
    "\n",
    "    data_list = [tuple(torch.rand(10, 10) for _ in range(10)) for _ in range(10)]\n",
    "    c.set_data_list(\"test_data_list\", data_list)\n",
    "    print(c.get(\"test_data_list\")[0], c.get(\"test_data_list\")[1])\n",
    "\n",
    "    #c.flushdb()\n",
    "    #print(c.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a0467-3465-4ff7-849c-8bfe84c6481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ag_weights = torch.load(\"ag_weights.pt\", map_location=device)\n",
    "c.set_data_list(\"ag_weights\", ag_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c74ee8ff-4068-4a47-ab9d-086cca490fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight features.0.bias\n",
      "{'peak.allocated': 287071288, 'total.allocated': 1154208, 'startup.allocated': 840976, 'replication.backlog': 0, 'clients.slaves': 0, 'clients.normal': 184552, 'aof.buffer': 0, 'lua.caches': 0, 'db.0': {'overhead.hashtable.main': 152, 'overhead.hashtable.expires': 0}, 'overhead.total': 1025680, 'keys.count': 3, 'keys.bytes-per-key': 104410, 'dataset.bytes': 128528, 'dataset.percentage': '41.032844543457031', 'peak.percentage': '0.40206319093704224', 'allocator.allocated': 1654032, 'allocator.active': 2117632, 'allocator.resident': 8269824, 'allocator-fragmentation.ratio': '1.2802847623825073', 'allocator-fragmentation.bytes': 463600, 'allocator-rss.ratio': '3.9052224159240723', 'allocator-rss.bytes': 6152192, 'rss-overhead.ratio': '11.57256031036377', 'rss-overhead.bytes': 87433216, 'fragmentation': '85.971725463867188', 'fragmentation.bytes': 94589848}\n"
     ]
    }
   ],
   "source": [
    "print(c.get(\"ag_weights\")[0], c.get(\"ag_weights\")[1])\n",
    "print(c.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f438c8-b609-4f36-9b10-30ccd90e71f9",
   "metadata": {},
   "source": [
    "## Pickel 사용 , chat gpt 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23dd855d-43a4-4bf5-9348-8d351426293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import redis\n",
    "from collections import OrderedDict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b7c8f-87cd-4824-8fb6-b27c3fb74484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상의 모델을 정의하고 학습하는 예제\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = SimpleModel()\n",
    "\n",
    "# 모델 학습 (여기에서는 더미 학습)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for _ in range(100):\n",
    "    inputs = torch.randn(10, 2)\n",
    "    labels = torch.randn(10, 1)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 학습된 모델을 OrderedDict로 변환\n",
    "state_dict = model.state_dict()\n",
    "ordered_dict_model = OrderedDict(state_dict)\n",
    "\n",
    "# Redis에 모델 저장\n",
    "redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "redis_client.set('model_A', pickle.dumps(ordered_dict_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a4972-5a71-475e-9026-73541327e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis에서 모델 읽어오기\n",
    "loaded_ordered_dict_model = pickle.loads(redis_client.get('model_A'))\n",
    "\n",
    "# 빈 모델 인스턴스 생성\n",
    "loaded_model = SimpleModel()\n",
    "\n",
    "# OrderedDict를 모델의 state_dict로 로드\n",
    "loaded_model.load_state_dict(loaded_ordered_dict_model)\n",
    "\n",
    "# 모델을 사용할 수 있습니다.\n",
    "input_data = torch.tensor([[1.0, 2.0]])  # 입력 데이터 예제\n",
    "output = loaded_model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc724e-f653-4d60-ba4d-d4fcf458845b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
